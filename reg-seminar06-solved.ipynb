{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в регрессионный анализ\n",
    "## Семинар 6. Модели с дамми-переменными (фиктивными переменными)\n",
    "*Алла Тамбовцева*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые для работы библиотеки и функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим строку кода, которая будет скрывать сообщения с предупреждениями в случае, если они возникают при создании новых столбцов на основе старых:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сюжет 1: парная регрессия с одной дамми-переменной\n",
    "\n",
    "Продолжим работать с данными из файла `english.csv` с прошлого практикума. \n",
    "\n",
    "**Напоминание про исследование.** Участникам эксперимента предлагают определить, является ли слово, которое они видят на экране, реально существующим в языке или нет (настоящее это слово или что-то выдуманное по правилам языка). Если участники узнают слово, они должны прочитать его вслух и нажать на специальную кнопку. Время, затраченное на узнавание слова фиксируется и измеряется в милисекундах: насколько быстро человек нажал на кнопку (реальное слово или нет, *lexical decision*), или прочитал слово (*word naming*).\n",
    "\n",
    "В файле отобраны только случаи с реально существующими словами. Переменные в файле:\n",
    "\n",
    "* `AgeSubject`: молодой участник эксперимента или нет;\n",
    "* `WordCategory`: часть речи (`N` – существительное, `V` – глагол);\n",
    "* `RTlexdec`: время в милисекундах, затраченное на узнавание слова;\n",
    "* `RTnaming`: время в милисекундах, затраченное на называние слова;\n",
    "* `WrittenFrequency`: мера того, насколько часто слово встречается в письменных текстах;\n",
    "* `LengthInLetters`: длина слова в буквах;\n",
    "* `FamilySize`: мера того, насколько богата морфологическая семья слова (как много однокоренных слов с разной частью речи);\n",
    "* `NumberSimplexSynsets`: мера того, насколько у слова много синонимов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и выберем только молодых участников эксперимента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = pd.read_csv(\"english.csv\")\n",
    "df = eng[eng[\"AgeSubject\"] == \"young\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку с данными мы уже познакомились в прошлый раз, перейдём сразу к моделям. Предположим, мы хотим построить модель, которая предсказывает время, затрачиваемое на узнавание слова, на основе его части речи. Давайте сначала пойдём по самому логичному пути и создадим бинарную переменную для части речи, где 1 соответствует глаголу, а 0 – существительному."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "\n",
    "Создайте бинарную переменную, где 1 соответствует глаголу, а 0 – существительному, и сохраните её в столбец `Verb` датафрейма `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"WordCategory\"] == \"V\" дает столбец из True/False\n",
    "# превращаем его в integer (True -> 1, False -> 0)\n",
    "\n",
    "df[\"Verb\"] = (df[\"WordCategory\"] == \"V\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "\n",
    "Используя созданную бинарную переменную, постройте парную линейную модель, которая предсказывает время, затрачиваемое на узнавание слова, на основе его части речи. Проинтерпретируйте полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               RTlexdec   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     10.03\n",
      "Date:                Mon, 14 Oct 2024   Prob (F-statistic):            0.00156\n",
      "Time:                        02:15:33   Log-Likelihood:                 1883.5\n",
      "No. Observations:                2284   AIC:                            -3763.\n",
      "Df Residuals:                    2282   BIC:                            -3752.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      6.4446      0.003   2314.049      0.000       6.439       6.450\n",
      "Verb          -0.0146      0.005     -3.167      0.002      -0.024      -0.006\n",
      "==============================================================================\n",
      "Omnibus:                      104.830   Durbin-Watson:                   1.958\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              118.911\n",
      "Skew:                           0.558   Prob(JB):                     1.51e-26\n",
      "Kurtosis:                       3.044   Cond. No.                         2.42\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model01 = ols(\"RTlexdec ~ Verb\", data = df).fit()\n",
    "print(model01.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Интерпретация.** Качество модели, если смотреть только на $R^2$, кажется низким, однако для моделей, где независимая переменная бинарная, это нормально. $R^2$ зависит, в частности, от дисперсии независимой переменной, а раз у нее всего два значения, 0 и 1, очень высокой она не будет (разнообразие значений, если их всего два, не может быть большим).\n",
    "\n",
    "* Уравнение модели: $\\widehat{\\text{RTlexdec}} = 6.44 - 0.01 \\times \\text{Verb}_i$. \n",
    "* Если $\\text{Verb}_i$ равен 0, то среднее время узнавания слова, согласно модели, равно 6.44 милисекундам. Содержательно это означает, что среднее время узнавания существительного (раз `Verb` равен 0), согласно модели, равно 6.44 мс. \n",
    "* Так как `Verb` – качественный показатель (глагол или существительное), об увеличении его на единицу говорить некорректно. Коэффициент при $\\text{Verb}_i$ показывает разницу в средних значениях зависимой переменной в двух группах. Среднее время узнавания глагола на 0.01 мс ниже, чем среднее время узнавания существительного, глаголы угадываются немного быстрее.\n",
    "* Несмотря на то, что значение оценки коэффициента при $\\text{Verb}_i$ кажется маленьким, он значимо отличается от нуля. Если посмотрим на наблюдаемое значение t-статистики (`t = -3.167`) и p-value (`P>|t| = 0.002`), мы сможем заключить, что гипотеза $H_0: b_1 = 0$ отвергается на любом уровне доверия (90%, 95%, 99%). \n",
    "* Для уровня доверия 95% можем дополнительно посмотреть на доверительный интервал для оценки коэффициента (`-0.024  -0.006`) и отметить, что он не накрывает 0, что тоже свидетельствует о несостоятельности гипотезы о равенстве коэффициента нулю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле, функция `ols()` умеет работать и с исходными качественными переменными. Если в качестве независимой переменной в уравнении внутри `ols()` используется текстовый столбец, функция сама создаст в рамках модели необходимую бинарную дамми-переменную. Проверим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3\n",
    "\n",
    "Используя исходную переменную `WordCategory`, постройте парную линейную модель, которая предсказывает время, затрачиваемое на узнавание слова, на основе его части речи. Проинтерпретируйте полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               RTlexdec   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     10.03\n",
      "Date:                Mon, 14 Oct 2024   Prob (F-statistic):            0.00156\n",
      "Time:                        02:39:47   Log-Likelihood:                 1883.5\n",
      "No. Observations:                2284   AIC:                            -3763.\n",
      "Df Residuals:                    2282   BIC:                            -3752.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept             6.4446      0.003   2314.049      0.000       6.439       6.450\n",
      "WordCategory[T.V]    -0.0146      0.005     -3.167      0.002      -0.024      -0.006\n",
      "==============================================================================\n",
      "Omnibus:                      104.830   Durbin-Watson:                   1.958\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              118.911\n",
      "Skew:                           0.558   Prob(JB):                     1.51e-26\n",
      "Kurtosis:                       3.044   Cond. No.                         2.42\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model02 = ols(\"RTlexdec ~ WordCategory\", data = df).fit()\n",
    "print(model02.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Интерпретация.** Та же самая, что и выше. Тут важно понимать, что запись `WordCategory[T.V]` в выдаче означает следующее: столбец на основе `WordCategory`, где `True` (сокращено до `T.`) соответствует значению `V`, а значение `False` – всем остальным. Другими словами, мы получили такую же модель, что и выше, но для ее получения нам не пришлось предварительно создавать бинарный столбец, где 1 (оно же `True`) соответствует глаголам. Python самостоятельно проделал эту операцию в рамках запуска `ols()`.\n",
    "\n",
    "Мы получили уравнение $\\widehat{\\text{RTlexdec}} = 6.44 - 0.01 \\times \\text{WordCategory[T.V]}_i$, которое легко сводится к $\\widehat{\\text{RTlexdec}} = 6.44 - 0.01 \\times \\text{Verb}_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию Python выбирает в качестве базовой категории ту, которая идёт первой по алфавиту. Давайте в качестве базовой категории выберем глагол (`V`). Как это сделать? Учесть в рамках функции `ols()` это не получится, нужно перекодировать данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4\n",
    "\n",
    "Используя функцию `Categorical()` из `pandas`, измените столбец `WordCategory` таким образом, чтобы значение `V` считалось первым, а значение `N` – вторым.\n",
    "\n",
    "Логика запуска функции:\n",
    "\n",
    "* на первом месте указываем название столбца, который перекодируем;\n",
    "* на втором месте – список значений в том порядке, который нас устраивает;\n",
    "* на третьем месте – аргумент `ordered=True`, чтобы зафиксировать порядок следования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# хотим, чтобы Python понимал, что V – это первое,\n",
    "# а N – второе\n",
    "\n",
    "df[\"WordCategory\"] = pd.Categorical(df[\"WordCategory\"], [\"V\", \"N\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeSubject</th>\n",
       "      <th>WordCategory</th>\n",
       "      <th>RTlexdec</th>\n",
       "      <th>RTnaming</th>\n",
       "      <th>WrittenFrequency</th>\n",
       "      <th>LengthInLetters</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>NumberSimplexSynsets</th>\n",
       "      <th>Verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>young</td>\n",
       "      <td>N</td>\n",
       "      <td>6.543754</td>\n",
       "      <td>6.145044</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>young</td>\n",
       "      <td>N</td>\n",
       "      <td>6.397596</td>\n",
       "      <td>6.246882</td>\n",
       "      <td>4.521789</td>\n",
       "      <td>5</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>young</td>\n",
       "      <td>N</td>\n",
       "      <td>6.304942</td>\n",
       "      <td>6.143756</td>\n",
       "      <td>6.505784</td>\n",
       "      <td>6</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>young</td>\n",
       "      <td>N</td>\n",
       "      <td>6.424221</td>\n",
       "      <td>6.131878</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>4</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>young</td>\n",
       "      <td>N</td>\n",
       "      <td>6.450597</td>\n",
       "      <td>6.198479</td>\n",
       "      <td>4.890349</td>\n",
       "      <td>4</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AgeSubject WordCategory  RTlexdec  RTnaming  WrittenFrequency  \\\n",
       "0      young            N  6.543754  6.145044          3.912023   \n",
       "1      young            N  6.397596  6.246882          4.521789   \n",
       "2      young            N  6.304942  6.143756          6.505784   \n",
       "3      young            N  6.424221  6.131878          5.017280   \n",
       "4      young            N  6.450597  6.198479          4.890349   \n",
       "\n",
       "   LengthInLetters  FamilySize  NumberSimplexSynsets  Verb  \n",
       "0                3    1.386294              0.693147     0  \n",
       "1                5    1.386294              1.098612     0  \n",
       "2                6    1.609438              2.484907     0  \n",
       "3                4    1.945910              1.098612     0  \n",
       "4                4    2.197225              2.484907     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# визуально выглядит так же, как и ранее, \n",
    "# но теперь для Python столбец WordCategory упорядоченный\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 5\n",
    "\n",
    "Используя обновлённую переменную `WordCategory`, постройте парную линейную модель, которая предсказывает время, затрачиваемое на узнавание слова, на основе его части речи. Сравните результаты с выдачей модели из задачи 3 и прокомментируйте различия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               RTlexdec   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     10.03\n",
      "Date:                Mon, 14 Oct 2024   Prob (F-statistic):            0.00156\n",
      "Time:                        02:46:18   Log-Likelihood:                 1883.5\n",
      "No. Observations:                2284   AIC:                            -3763.\n",
      "Df Residuals:                    2282   BIC:                            -3752.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept             6.4299      0.004   1747.692      0.000       6.423       6.437\n",
      "WordCategory[T.N]     0.0146      0.005      3.167      0.002       0.006       0.024\n",
      "==============================================================================\n",
      "Omnibus:                      104.830   Durbin-Watson:                   1.958\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              118.911\n",
      "Skew:                           0.558   Prob(JB):                     1.51e-26\n",
      "Kurtosis:                       3.044   Cond. No.                         3.07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model03 = ols(\"RTlexdec ~ WordCategory\", data = df).fit()\n",
    "print(model03.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Интерпретация.** Мы поменяли категории местами, поэтому:\n",
    "\n",
    "* знак при `WordCategory` изменился по сравнению с предыдущей моделью;\n",
    "* оценка константы $\\hat{b}_0$ тоже изменилась;\n",
    "* $R^2$ и остальные характеристики модели остались прежними.\n",
    "\n",
    "Итого:\n",
    "\n",
    "* Уравнение модели: $\\widehat{\\text{RTlexdec}} = 6.43 + 0.01 \\times \\text{WordCategory[T.N]}_i$, которое легко сводится к $\\widehat{\\text{RTlexdec}} = 6.43 + 0.01 \\times \\text{Noun}_i$. \n",
    "* Согласно модели, среднее время узнавания слова, если оно является глаголом, равно 6.43 милисекундам. Среднее время узнавания существительного на 0.01 мс выше, чем среднее время угадывания глагола, глаголы угадываются немного быстрее.\n",
    "* Так как мы уже выяснили, что оценка коэффициента при `WordCategory`, равная 0.01, отвечает за разницу в среднем времени узнавания существительных и глаголов, несложно понять, почему значения `Intercept` в модели из задачи 3 и в модели из этой задачи равны соответственно 6.44 и 6.43."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сюжет 2: множественная модель с одной дамми-переменной\n",
    "\n",
    "В прошлый раз мы строили множественную регрессионную модель, которая предсказывала время, затрачиваемое на узнавание слова, в зависимости от его грамматических характеристик, выраженных в числовом виде. Построим модель, которая включает не только количественные, но и качественные характеристики слова!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте линейную модель, которая объясняет, как время, затрачиваемое на узнавание слова, зависит от его встречаемости в письменных текстах, размера морфологической семьи и части речи. Проинтерпретируйте полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               RTlexdec   R-squared:                       0.431\n",
      "Model:                            OLS   Adj. R-squared:                  0.431\n",
      "Method:                 Least Squares   F-statistic:                     576.4\n",
      "Date:                Mon, 14 Oct 2024   Prob (F-statistic):          8.85e-279\n",
      "Time:                        03:06:03   Log-Likelihood:                 2523.1\n",
      "No. Observations:                2284   AIC:                            -5038.\n",
      "Df Residuals:                    2280   BIC:                            -5015.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept             6.6240      0.005   1214.527      0.000       6.613       6.635\n",
      "WordCategory[T.N]     0.0130      0.003      3.728      0.000       0.006       0.020\n",
      "WrittenFrequency     -0.0310      0.001    -25.471      0.000      -0.033      -0.029\n",
      "FamilySize           -0.0206      0.003     -7.535      0.000      -0.026      -0.015\n",
      "==============================================================================\n",
      "Omnibus:                       41.694   Durbin-Watson:                   1.969\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               47.074\n",
      "Skew:                           0.283   Prob(JB):                     6.00e-11\n",
      "Kurtosis:                       3.417   Cond. No.                         19.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model04 = ols(\"RTlexdec ~ WordCategory + WrittenFrequency + FamilySize\", data = df).fit()\n",
    "print(model04.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Интерпретация.**\n",
    "\n",
    "* Уравнение модели: $$\\widehat{\\text{RTlexdec}} = 6.62 + 0.01 \\times \\text{WordCategory[T.N]}_i - 0.03 \\times \\text{WrittenFrequency}_i - 0.02 \\times \\text{FamilySize}_i.$$\n",
    "* Согласно модели, среднее время узнавания глагола (`WordCategory[T.N]` равно 0), который выдуман и не встречается в письменных текстах (`WrittenFrequency` равно 0) и у которого нет однокоренных слов (`FamilySize` равно 0) составляет 6.62 милисекунды. Ситуация в данном случае не очень реалистичная, но это формальный смысл константы `Intercept`.\n",
    "* При прочих равных условиях, среднее время узнавания существительных на 0.01 мс выше среднего времени узнавания глаголов. То есть, если мы будем сравнивать среднее время узнавания двух слов, которые встречаются в письменных текстах с одинаковой частотой и которые имеют одинаковое число однокоренных слов, значение для существительного будет выше на 0.01 мс.\n",
    "* При прочих равных условиях, при увеличении встречаемости слова в письменных текстах на единицу, время узнавания слова, в среднем, уменьшается на 0.03 мс. При прочих равных условиях здесь – если мы сравниваем слова одной и той же части речи и с одинаковым количеством однокоренных слов.\n",
    "* При прочих равных условиях, при увеличении числа однокоренных слов на единицу, время узнавания слова, в среднем, уменьшается на 0.02 мс. При прочих равных условиях здесь – если мы сравниваем слова одной и той же части речи, одинаково часто встречающиеся в письменных текстах.\n",
    "* Так как наблюдаемые значения t-статистики для всех оценок коэффициентов по модулю превышают 3, и p-value везде равно 0, на любом уровне доверия (90%, 95%, 99%) или любом уровне значимости (10%, 5%, 1%) эффект каждой независимой переменной можно считать значимо отличным от нуля.\n",
    "* Качество модели нельзя назвать плохим, модель объясняет 43% дисперсии зависимой переменной. Другими словами, изменчивость времени угадывания слова на 43% можно объяснить изменчивостью встречаемости слова в письменных текстах и количества однокоренных слов, а также принадлежностью к разным частям речи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сюжет 3: множественная модель с несколькими дамми-переменными\n",
    "\n",
    "Давайте частично воспроизведем модель из статьи *E.Patacchini et al \"Information Transmission in a Social Network: A Field Experiment\"* и выясним, зависит ли успешность групповой работы от типа устройства сети сообщества, при условии, что тип сети определяет характер передачи информации, которая приближает группу к выигрышу.\n",
    "\n",
    "В этой статье описывается экспериментальная игра, в которой участвовали ученики одной школы Италии. Школьников случайным образом распределяли на группы по 5 человек и давали каждому индивидуальное задание – угадать все цвета элементов одежды персонажа (шапка, рубашка, брюки, перчатки, ботинки), который показывался им на картинке в приложении. Каждому участнику был достоверно известен только цвет какого-то одного элемента одежды. Идея понятна: в идеальной ситуации в группе из пяти человек каждый может поделиться своей частью информации с другим, узнать все пять элементов одежды и остаться в выигрыше. Но все не так просто. Школьники не знают, с кем они находятся в группе, эта информация им доступна лишь частично: кто-то знает имена трех членов группы, кто-то – только двух, кто-то – только одного. Никакого чата в игре нет и участники не могут его создать, они могут лишь вживую, зная имя человека, обменяться с ним информацией.\n",
    "\n",
    "Таким образом, группы из пяти человек устроены по-разному, по разным типам сети.\n",
    "\n",
    "* Первый тип сети: довольно базовый, участники знают одного-двух участников группы, при этом есть наиболее осведомленный член группы, который знает трех участников.\n",
    "\n",
    "* Второй тип сети: явное преимущество у одного члена группы, он знает имена всех четырех участников, остальные – лишь двоих.\n",
    "\n",
    "* Третий тип сети: более равномерное число связей, все участники, кроме одного, знают имена двух-трех участников.\n",
    "\n",
    "За угадывания цветов игроки получают баллы, попытки с неправильными ответами штрафуются. Участники, набравшие наибольшее число очков, могли выиграть суммы от 0 до 15 евро, выигрыш вручался в виде подарочных карт от Amazon на определенную сумму.\n",
    "\n",
    "**Итого:** интересно посмотреть, каким образом тип сети (а, следовательно, и конфигурация системы передачи информации) сказывается на групповом выигрыше. Если смотреть только на устройство сети, кажется, что вторая сеть, где есть участник, знающий всех, идеальна, потому что он будет центральным «узлом» передачи информации для всех игроков. Но в реальности, где рациональный выбор все же существует, все может оказаться иначе: центральному игроку, знающему всех, может быть невыгодно служить источником информации для остальных, так как передавая правдивую информацию он, в том числе, повышает шансы других угадать больше ответов и получить выигрыш.\n",
    "\n",
    "Загрузим данные с результатами эксперимента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>phase</th>\n",
       "      <th>character</th>\n",
       "      <th>idusers</th>\n",
       "      <th>idnetwork</th>\n",
       "      <th>hint_cloth</th>\n",
       "      <th>hint_col</th>\n",
       "      <th>hat_guess</th>\n",
       "      <th>shirt_guess</th>\n",
       "      <th>pant_guess</th>\n",
       "      <th>...</th>\n",
       "      <th>score_glove</th>\n",
       "      <th>score</th>\n",
       "      <th>num_corrects</th>\n",
       "      <th>num_mistakes</th>\n",
       "      <th>grey</th>\n",
       "      <th>winner</th>\n",
       "      <th>grp_act_num</th>\n",
       "      <th>grp_num_corrects</th>\n",
       "      <th>grp_num_mistakes</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Freddie</td>\n",
       "      <td>358</td>\n",
       "      <td>1</td>\n",
       "      <td>cappello</td>\n",
       "      <td>nero</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Piergiorgio</td>\n",
       "      <td>603</td>\n",
       "      <td>1</td>\n",
       "      <td>guanti</td>\n",
       "      <td>bianco</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Marshall</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>cappello</td>\n",
       "      <td>bianco</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alberto</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>guanti</td>\n",
       "      <td>blu</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Teseo</td>\n",
       "      <td>1417</td>\n",
       "      <td>1</td>\n",
       "      <td>cappello</td>\n",
       "      <td>arancione</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  phase    character  idusers  idnetwork hint_cloth   hint_col  \\\n",
       "0           1    1.0      Freddie      358          1   cappello       nero   \n",
       "1           3    1.0  Piergiorgio      603          1     guanti     bianco   \n",
       "2           8    1.0     Marshall      447          1   cappello     bianco   \n",
       "3          14    1.0      Alberto      184          1     guanti        blu   \n",
       "4          18    1.0        Teseo     1417          1   cappello  arancione   \n",
       "\n",
       "   hat_guess  shirt_guess  pant_guess  ...  score_glove  score  num_corrects  \\\n",
       "0        9.0          5.0         4.0  ...         10.0   50.0           5.0   \n",
       "1       10.0         10.0         2.0  ...         10.0   20.0           2.0   \n",
       "2        8.0          2.0         2.0  ...         10.0   50.0           5.0   \n",
       "3        4.0          5.0         7.0  ...         10.0    5.0           2.0   \n",
       "4        2.0          3.0         1.0  ...         10.0   35.0           4.0   \n",
       "\n",
       "   num_mistakes  grey  winner  grp_act_num  grp_num_corrects  \\\n",
       "0           0.0   0.0     1.0          5.0              25.0   \n",
       "1           0.0   3.0     1.0          5.0              11.0   \n",
       "2           0.0   0.0     1.0          5.0              21.0   \n",
       "3           3.0   0.0     0.0          5.0              16.0   \n",
       "4           1.0   0.0     1.0          5.0              15.0   \n",
       "\n",
       "   grp_num_mistakes  pos  \n",
       "0               0.0    a  \n",
       "1               2.0    a  \n",
       "2               1.0    a  \n",
       "3               8.0    a  \n",
       "4               4.0    a  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"networks.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, построим линейную модель, где зависимая переменная – число правильных ответов на группу, а независимая – тип сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       grp_num_corrects   R-squared:                       0.025\n",
      "Model:                            OLS   Adj. R-squared:                  0.024\n",
      "Method:                 Least Squares   F-statistic:                     17.05\n",
      "Date:                Mon, 14 Oct 2024   Prob (F-statistic):           4.12e-05\n",
      "Time:                        03:44:17   Log-Likelihood:                -2064.8\n",
      "No. Observations:                 660   AIC:                             4134.\n",
      "Df Residuals:                     658   BIC:                             4143.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     14.7510      0.589     25.036      0.000      13.594      15.908\n",
      "idnetwork      1.0789      0.261      4.129      0.000       0.566       1.592\n",
      "==============================================================================\n",
      "Omnibus:                      311.082   Durbin-Watson:                   1.979\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.778\n",
      "Skew:                          -0.073   Prob(JB):                     1.03e-08\n",
      "Kurtosis:                       1.853   Cond. No.                         7.24\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_nw = ols(\"grp_num_corrects ~ idnetwork\", data).fit()\n",
    "print(model_nw.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, которую мы только что построили, некорректная. Почему? Посмотрим на `idnetwork`. По-хорошему, у нас в модели должно быть две фиктивные переменные, одна для сравнения второго типа с первым, вторая – для сравнения третьего типа с первым. Здесь такого не происходит, потому что тип столбца `idnetwork` целочисленный, и Python воспринимает его как полноценную числовую переменную. Как это поправить? Можно изменить тип переменной в датафрейме глобально, а можно просто учесть это в формуле `ols()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       grp_num_corrects   R-squared:                       0.046\n",
      "Model:                            OLS   Adj. R-squared:                  0.043\n",
      "Method:                 Least Squares   F-statistic:                     15.89\n",
      "Date:                Mon, 14 Oct 2024   Prob (F-statistic):           1.82e-07\n",
      "Time:                        03:44:20   Log-Likelihood:                -2057.7\n",
      "No. Observations:                 660   AIC:                             4121.\n",
      "Df Residuals:                     657   BIC:                             4135.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept            16.4615      0.392     41.952      0.000      15.691      17.232\n",
      "C(idnetwork)[T.2]    -0.7542      0.548     -1.376      0.169      -1.830       0.322\n",
      "C(idnetwork)[T.3]     2.0000      0.519      3.853      0.000       0.981       3.019\n",
      "==============================================================================\n",
      "Omnibus:                      360.199   Durbin-Watson:                   2.021\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.621\n",
      "Skew:                          -0.001   Prob(JB):                     6.77e-09\n",
      "Kurtosis:                       1.830   Cond. No.                         3.95\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# C() – от Categorical, то есть\n",
    "# смотри на переменную как на качественную, категориальную\n",
    "\n",
    "mod1 = ols(\"grp_num_corrects ~ C(idnetwork)\", data).fit()\n",
    "print(mod1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь все нормально. Проинтерпретируем полученную модель!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Уравнение модели: $$\\widehat{\\text{grp_num_corrects}_i} = 16.46 - 0.75 \\times \\text{C(idnetwork)[T.2]}_i + 2 \\times \\text{C(idnetwork)[T.3]}_i,$$ перепишем для простоты:\n",
    "$$\n",
    "\\widehat{\\text{grp_num_corrects}_i} = 16.46 - 0.75 \\times \\text{Network2}_i + 2 \\times \\text{Network3}_i\n",
    "$$\n",
    "\n",
    "* `Intercept`: константа модели, содержательно это среднее значение зависимой переменной в базовой категории. Базовая категория здесь – это группы, устроенные по первому типу сети, с `idnetwork` равной 1, так как эта категория «выкинута» из выдачи. То есть, мы можем сказать, что среднее общегрупповое число верных ответов в группах, устроенных по типу первой сети, примерно равно 16.\n",
    "\n",
    "* `C(idnetwork)[T.2]`: коэффициент при втором типе сети, показывает разницу средних значений зависимой переменной в этой категории и базовой категории. Можем сказать, что среднее общегрупповое число верных ответов в группах, устроенных по типу второй сети, ниже на 0.75 (то есть примерно на 1), чем среднее число верных ответов в группах, устроенных по типу первой сети. Однако этот коэффициент является незначимым на любом разумном уровне значимости (и на 5%, и на 10%) в силу высокого p-value 0.169, поэтому интерпретировать его особого смысла нет.\n",
    "\n",
    "* `C(idnetwork)[T.3]`: коэффициент при третьем типе сети, показывает разницу средних значений зависимой переменной в этой категории и базовой категории. Можем сказать, что среднее общегрупповое число верных ответов в группах, устроенных по типу третьей сети, на 2 выше, чем среднее число верных ответов в группах, устроенных по типу первой сети. Оценка коэффициента в данном случае статистически значима на 5%-ном уровне значимости (и на 1%-ном тоже), поэтому различия точно есть. Выходит, третий тип сети самый выгодный, если нас интересует максимизация выигрыша всей группы."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
